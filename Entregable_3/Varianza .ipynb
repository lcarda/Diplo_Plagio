{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jsq8jMXfmaxT"
   },
   "source": [
    "#Entregable 3\n",
    "##Grupo A\n",
    "###Diplomatura de Ciencias de Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEYrc3f3m6WX"
   },
   "source": [
    "**Pablo:** en el presente entregable vas a encontrar la visualización que hicimos del corpus de textos suministrados junto a un breve análisis del mismo.\n",
    "\n",
    "Muchas gracias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHdZ3rwRmqpl"
   },
   "source": [
    "####Insumos para la resolución del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVgjyb8fnbli"
   },
   "source": [
    "####Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1ZKl3pbeBHR",
    "outputId": "06234353-6544-4bb6-cf19-68211e1b3cc6",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y5UGmc7ivb3S",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nBBXaqfivefI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus=pd.read_csv('intrinsic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88NAtDeQhcWc",
    "outputId": "012fc14a-655a-4ba8-f8fd-d975900c1521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4753 entries, 0 to 4752\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     4753 non-null   int64 \n",
      " 1   filename  4753 non-null   object\n",
      " 2   text      4753 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 111.5+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kecwocD92NWC",
    "outputId": "39956873-52ce-40a1-dfdc-d3ec8daa7741",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from textstat) (0.14.0)\n",
      "Requirement already satisfied: lexicalrichness in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from lexicalrichness) (1.10.1)\n",
      "Requirement already satisfied: textblob>=0.15.3 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from lexicalrichness) (0.17.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from lexicalrichness) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from lexicalrichness) (3.7.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from scipy>=1.0.0->lexicalrichness) (1.25.0)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from textblob>=0.15.3->lexicalrichness) (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from matplotlib->lexicalrichness) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from pandas->lexicalrichness) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from pandas->lexicalrichness) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from nltk>=3.1->textblob>=0.15.3->lexicalrichness) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from nltk>=3.1->textblob>=0.15.3->lexicalrichness) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from nltk>=3.1->textblob>=0.15.3->lexicalrichness) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from nltk>=3.1->textblob>=0.15.3->lexicalrichness) (4.65.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lexicalrichness) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\envs\\plagio\\lib\\site-packages (from click->nltk>=3.1->textblob>=0.15.3->lexicalrichness) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat\n",
    "!pip install lexicalrichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2agwH8DJvn5I",
    "outputId": "9ed417e2-f04b-4356-af49-e87de3505a7d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import operator\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.colors as mc\n",
    "import nltk\n",
    "import numpy as np\n",
    "import textstat\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import textstat\n",
    "from lexicalrichness import LexicalRichness\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.tag import pos_tag, map_tag\n",
    "\n",
    "\n",
    " # Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpEyOLQ3yv4r"
   },
   "source": [
    "##Segmentación del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AwW827UtkSy"
   },
   "source": [
    "Con este código segmentamos el texto en oraciones (sentSegmentation) y en párrafos (paraSegmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3LL4Hu4lzB65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Segmentation:\n",
    "\n",
    "    def __init__(self, text):\n",
    "\n",
    "        self.text = text\n",
    "\n",
    "    def sentSegmentation(self):\n",
    "\n",
    "        return sent_tokenize(self.text)\n",
    "\n",
    "    def paraSegmentation(self):\n",
    "\n",
    "        texto = self.text.split(\"\\n\\n\")\n",
    "\n",
    "        return list(filter(bool, texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Wq9kROLh091J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metricas:\n",
    "\n",
    "    def __init__(self, text):\n",
    "\n",
    "        self.text = text\n",
    "\n",
    "    def sentSegmentation(self):\n",
    "\n",
    "        return sent_tokenize(self.text)\n",
    "\n",
    "\n",
    "    def paraSegmentation(self):\n",
    "\n",
    "        texto = self.text.split(\"\\n\\n\")\n",
    "\n",
    "        return list(filter(bool, texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU4AkJ2hX4He"
   },
   "source": [
    "## Limpieza del texto, metricas y base de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-9IH_XRYjTm"
   },
   "source": [
    "para la columnas con metricas para texto y texto limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QAFJA7kQYP8U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "def calculate_automated_readability_index(text):\n",
    "    return textstat.automated_readability_index(text)\n",
    "#Índice de Legibilidad Automatizado (Automated Readability Index): Es una medida que estima\n",
    "#el nivel de dificultad de lectura de un texto en inglés. Utiliza una fórmula matemática para\n",
    "#calcular un puntaje que representa el grado de dificultad de lectura. Un puntaje más alto indica\n",
    "#un texto más difícil de leer, mientras que un puntaje más bajo indica un texto más fácil de leer.\n",
    "\n",
    "def calculate_dale_chall_readability_score(text):\n",
    "    return textstat.dale_chall_readability_score(text)\n",
    "\n",
    "#Puntaje de Legibilidad Dale-Chall (Dale-Chall Readability Score): Es otra medida que evalúa la dificultad\n",
    "#de lectura de un texto en inglés. A diferencia de otros tests, este utiliza una tabla de búsqueda de las 3000\n",
    "#palabras más comúnmente utilizadas en inglés. El puntaje resultante indica el nivel de grado de lectura utilizando\n",
    "#la Fórmula Nueva de Dale-Chall.\n",
    "\n",
    "\n",
    "def flesch_reading_ease(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "def count_sentences(text):\n",
    "    return textstat.sentence_count(text)\n",
    "\n",
    "def count_polysyllables(text):\n",
    "    return textstat.polysyllabcount(text)\n",
    "\n",
    "def count_monosyllables(text):\n",
    "    return textstat.monosyllabcount(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46kR9g6eYsLJ"
   },
   "source": [
    "Para limpieza del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "apKH5TxSYauo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPECIAL_CHARACTERS = []\n",
    "\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(0, 32)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(33, 48)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(58, 65)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(91, 97)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(123, 225)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(226, 233)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(234, 237)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(238, 241)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(242, 243)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(244, 250)))\n",
    "SPECIAL_CHARACTERS.extend(map(chr, range(251, 880)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QRYd9A_mYdiF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CleanText():\n",
    "\n",
    "    def __init__(self, text, language=\"english\"):\n",
    "\n",
    "        self.text = text\n",
    "\n",
    "        self.language = language\n",
    "\n",
    "        self.clean_text = None\n",
    "\n",
    "        self.remove_spec_text = None\n",
    "\n",
    "        self.remove_stop_text = None\n",
    "\n",
    "        self.lemma_text = None\n",
    "\n",
    "    def removePatterns(self):\n",
    "\n",
    "        replacements = (\n",
    "            (\"á\", \"a\"),\n",
    "            (\"é\", \"e\"),\n",
    "            (\"í\", \"i\"),\n",
    "            (\"ó\", \"o\"),\n",
    "            (\"ú\", \"u\"),\n",
    "        )\n",
    "\n",
    "        self.text = str(self.text)\n",
    "\n",
    "        self.clean_text = self.text.lower()\n",
    "\n",
    "        self.clean_text = re.sub(r\"\\s{2,}\", \" \", self.clean_text)\n",
    "\n",
    "        self.clean_text = re.sub(r\"\\n\", \" \", self.clean_text)\n",
    "\n",
    "        self.clean_text = re.sub(r\"\\d+\", \" \", self.clean_text)\n",
    "\n",
    "        self.clean_text = re.sub(r\"^\\s+\", \" \", self.clean_text)\n",
    "\n",
    "        self.clean_text = re.sub(r\"\\s+\", \" \", self.clean_text)\n",
    "\n",
    "        for a, b in replacements:\n",
    "\n",
    "            self.clean_text = self.clean_text.replace(a, b).replace(a.upper(), b.upper())\n",
    "\n",
    "        return self.clean_text\n",
    "\n",
    "    def removeSpecChars(self):\n",
    "\n",
    "        remove_patterns = self.removePatterns()\n",
    "\n",
    "        tokens = list(word_tokenize(remove_patterns))\n",
    "\n",
    "        clean_tokens = tokens.copy()\n",
    "\n",
    "        for i in range(len(clean_tokens)):\n",
    "\n",
    "            for special_character in SPECIAL_CHARACTERS:\n",
    "\n",
    "                clean_tokens[i] = clean_tokens[i].replace(special_character, '')\n",
    "\n",
    "        clean_tokens = [token for token in clean_tokens if token]\n",
    "\n",
    "        self.remove_spec_text = \" \".join(clean_tokens)\n",
    "\n",
    "        return self.remove_spec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F8FQp4QDH2EA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#no correr simplemente llamar el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADZmVZkV541U",
    "outputId": "4e2d40b4-e76e-4dcd-9887-210310ebb2ef",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4753 entries, 0 to 4752\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     4753 non-null   int64 \n",
      " 1   filename  4753 non-null   object\n",
      " 2   text      4753 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 111.5+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "yAw_-sNA5jqN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus['automa_readability_ind_or'] = corpus['text'].apply(calculate_automated_readability_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "8FBmbAiI9WO8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus['dale_chall_readability_or'] = corpus['text'].apply(calculate_dale_chall_readability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "eA0iSR_IQP4-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus['count_polysyllables_or'] = corpus['text'].apply(count_polysyllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "BhYoDAlZQQ8v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus['count_monosyllables_or'] = corpus['text'].apply(count_monosyllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Zs2UXti9QVH-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus['flesch_reading_ease_or'] = corpus['text'].apply(flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "yPoSUXTMQW0G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "corpus['text_limpio'] = corpus['text'].apply(lambda value: CleanText(value).removeSpecChars())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "aR5MyTNG7JCn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, 4752 to 4752\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   index                      1 non-null      object \n",
      " 1   filename                   1 non-null      object \n",
      " 2   text                       1 non-null      object \n",
      " 3   automa_readability_ind_or  1 non-null      float64\n",
      " 4   dale_chall_readability_or  1 non-null      float64\n",
      " 5   count_polysyllables_or     1 non-null      int64  \n",
      " 6   count_monosyllables_or     1 non-null      int64  \n",
      " 7   flesch_reading_ease_or     1 non-null      float64\n",
      " 8   text_limpio                1 non-null      object \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 188.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "yAw_-sNA5jqN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus['automa_readability_ind_cl'] = corpus['text_limpio'].apply(calculate_automated_readability_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "8FBmbAiI9WO8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus['dale_chall_readability_cl'] = corpus['text_limpio'].apply(calculate_dale_chall_readability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "eA0iSR_IQP4-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus['count_polysyllables_cl'] = corpus['text_limpio'].apply(count_polysyllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "BhYoDAlZQQ8v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus['count_monosyllables_cl'] = corpus['text_limpio'].apply(count_monosyllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Zs2UXti9QVH-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus['flesch_reading_ease_cl'] = corpus['text_limpio'].apply(flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "jcJ5ntXGZYA9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#corpus.to_csv('intrinsic_with_metrics_final.csv', index=False) #archivo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus=pd.read_csv('intrinsic_with_metrics_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "585Vi7KeAjyq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bmT9l3SuApfq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus1 = corpus.drop(columns=['filename','index','text','text_limpio']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizamos y hacemos Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wcl-dTHzzNfR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scalerMM = MinMaxScaler()\n",
    "scalerMM.fit(corpus1)\n",
    "corpus_MinMax=scalerMM.transform(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7yfhAigWFs65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = VarianceThreshold(threshold=0)\n",
    "select.fit(corpus_MinMax)\n",
    "var_corpusMM=select.transform(corpus_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_corpusMM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos Variance Threshold al corpus sin Estandarizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7yfhAigWFs65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "select1 = VarianceThreshold(50)\n",
    "select1.fit(corpus1)\n",
    "var_corpus=select1.transform(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['count_polysyllables_or', 'count_monosyllables_or',\n",
       "       'flesch_reading_ease_or', 'automa_readability_ind_cl',\n",
       "       'dale_chall_readability_cl', 'count_polysyllables_cl',\n",
       "       'count_monosyllables_cl', 'flesch_reading_ease_cl'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos y hacemos Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wcl-dTHzzNfR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scalerN = Normalizer()\n",
    "scalerN.fit(corpus1)\n",
    "corpus_N=scalerN.transform(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7yfhAigWFs65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = VarianceThreshold(threshold=0)\n",
    "select.fit(corpus_N)\n",
    "var_corpusN=select.transform(corpus_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4753, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_corpusN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
